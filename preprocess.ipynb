{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('a.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': '62695603181473949687510174314055387106', 'category': 'perceptron', 'params': '{\"category\":\"perceptron\",\"model_name\":\"lucua\",\"datasets\":[\"64460f77a4832018aed11964\",\"64460f77a4832018aed119c5\",\"64460f77a4832018aed1190f\",\"64460f77a4832018aed11957\"],\"class_names\":null,\"epoch_num\":10,\"input_dim\":[32,32],\"structure\":[20,20,20],\"activation_name\":\"ReLU\",\"val_percent\":1,\"data_augmentation_config\":null,\"batch_size\":64,\"embedding_dim\":0,\"rnn_units\":0,\"seq_length\":0}', 'datasets': [{'name': 'dreams', 'link': 'https://cdn.generative.xyz/ai-school-dataset/dreams-by-joshua-bagley.zip'}, {'name': 'machine comics', 'link': 'https://cdn.generative.xyz/ai-school-dataset/machine-comics-by-roni-block.zip'}, {'name': 'act of emotion', 'link': 'https://cdn.generative.xyz/ai-school-dataset/act-of-emotion-by-kelly-milligan.zip'}, {'name': 'daisies', 'link': 'https://cdn.generative.xyz/ai-school-dataset/daisies-by-natthakit-susanthitanon-nsmag.zip'}]}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rein = []\n",
    "all = []\n",
    "\n",
    "for user_info in data:\n",
    "    new_user_info = {}\n",
    "    if user_info[\"category\"] == \"perceptron\":\n",
    "        new_user_info = {\n",
    "            \"model_id\": user_info[\"model_id\"],\n",
    "            \"datasets\": []\n",
    "        }\n",
    "        for dataset in user_info[\"datasets\"]:\n",
    "            dataset_name = dataset[\"name\"]\n",
    "            dataset_url = dataset[\"link\"].replace(\"https://cdn.generative.xyz\", \"https://cdn.eternalai.org\")\n",
    "            new_user_info[\"datasets\"].append({\n",
    "                'name': dataset_name,\n",
    "                'link': dataset_url\n",
    "            })\n",
    "        rein.append((user_info[\"category\"], new_user_info))\n",
    "    else:\n",
    "        new_user_info = {\n",
    "            \"model_id\": user_info[\"model_id\"],\n",
    "            \"datasets\": []\n",
    "        }\n",
    "        for dataset in user_info[\"datasets\"]:\n",
    "            dataset_url = dataset[\"link\"].replace(\"https://cdn.generative.xyz\", \"https://cdn.eternalai.org\")\n",
    "            new_user_info[\"datasets\"].append(dataset_url)\n",
    "        all.append((user_info[\"category\"], new_user_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0.5\n",
    "indices = int(len(all) * 0.5)\n",
    "eggar = []\n",
    "james = []\n",
    "\n",
    "for i, info_user in enumerate(all):\n",
    "    if i < indices:\n",
    "        eggar.append(info_user)\n",
    "    else:\n",
    "        james.append(info_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eggar.json', 'w') as f:\n",
    "    json.dump(eggar, f)\n",
    "\n",
    "with open('james.json', 'w') as f:\n",
    "    json.dump(james, f)\n",
    "\n",
    "with open(\"rein.json\", 'w') as f:\n",
    "    json.dump(rein, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgdown\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gdown\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "def download_and_unzip(urls):\n",
    "    \"\"\"\n",
    "    Downloads files from a list of URLs and zips them into a single zip file.\n",
    "    \n",
    "    Args:\n",
    "        urls (list): List of URLs of files to download.\n",
    "        zip_filename (str): Name of the zip file to create.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the created zip file.\n",
    "    \"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()  # Create a temporary directory\n",
    "    # Download files\n",
    "    downloaded_files = []\n",
    "    for url in urls:\n",
    "        filename = os.path.basename(url)\n",
    "        file_path = os.path.join(temp_dir, filename)\n",
    "        gdown.download(url, file_path, quiet=False)    \n",
    "        downloaded_files.append(file_path)\n",
    "    # extract all zip from downloaded_files to tempdir\n",
    "    for file in downloaded_files:\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "                \n",
    "    \n",
    "    return temp_dir\n",
    "\n",
    "# Example usage:\n",
    "urls = james[0][1][\"datasets\"]\n",
    "tmp_dir = download_and_unzip(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "file_paths = glob.glob(os.path.join('./output_models', '*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_MODEL_API = \"https://api-dojo.eternalai.org/api/admin/dojo/upload-output?admin_key=eai2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_id': '167968787483025614288362991064864198942', 'status': 'failed'}, {'model_id': '339973558767979115727731598339190197639', 'status': 'failed'}, {'model_id': '211833729630507175481322081149641641426', 'status': 'failed'}, {'model_id': '65573568706489280671739505212994990938', 'status': 'failed'}, {'model_id': '287242131161617686266990956852754277296', 'status': 'failed'}, {'model_id': '19297210931970656590007760867486325157', 'status': 'failed'}, {'model_id': '49899555801964080715022352495758776711', 'status': 'failed'}, {'model_id': '277893393319227609979976460873181860146', 'status': 'failed'}, {'model_id': '117402081594603436394449231176695896341', 'status': 'failed'}, {'model_id': '97376534365236863115963077926047938871', 'status': 'failed'}, {'model_id': '271132442866581491993247202703339268515', 'status': 'failed'}, {'model_id': '289143157313515958515363909719271157294', 'status': 'failed'}, {'model_id': '327126948381781979731070700624374978417', 'status': 'failed'}, {'model_id': '332627106859141432512193871151302255834', 'status': 'failed'}, {'model_id': '2446982355074135744027610809324785192', 'status': 'failed'}, {'model_id': '103630747578511523318636261510977201328', 'status': 'failed'}, {'model_id': '47028607029793748087431231745751552825', 'status': 'failed'}, {'model_id': '271588251671429209268929755813043179744', 'status': 'failed'}, {'model_id': '324102210988860791851828368972553406968', 'status': 'failed'}]\n"
     ]
    }
   ],
   "source": [
    "print(model_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import requests\n",
    "\n",
    "with open('model_status.json', 'w') as f:\n",
    "    json.dump(model_status, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_MODEL_API = \"https://api-dojo.eternalai.org/api/admin/dojo/upload-output?admin_key=eai2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_output(output_path):\n",
    "    model_id = os.path.basename(output_path).split('.')[0]\n",
    "    payload = {'model_id': model_id}\n",
    "    files=[\n",
    "    ('output',(output_path.split('/')[-1], open(output_path,'rb'), 'application/json'))\n",
    "    ]\n",
    "    headers = {}\n",
    "    response = requests.request(\"POST\", UPLOAD_MODEL_API, headers=headers, data=payload, files=files)\n",
    "    status = {\n",
    "        \"response\": response.text,\n",
    "        \"model_id\": model_id\n",
    "    }\n",
    "    if response.status_code == 200:\n",
    "        status[\"status\"] = \"success\"\n",
    "    else:\n",
    "        status[\"status\"] = \"failed\"\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join('./output_models', '*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:26<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_path in tqdm.tqdm(file_paths, total=len(file_paths)):\n",
    "    status = upload_output(file_path)\n",
    "    model_status.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_status.json', 'w') as f:\n",
    "    json.dump(model_status, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"Model is trained or in training\"}', 'status': 'failed'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"mongo: no documents in result\"}', 'status': 'failed'}, {'response': '{\"status\":1}', 'status': 'success'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}, {'response': '{\"error\":\"error decoding key completed_at: cannot decode UTC datetime into an integer type\"}', 'status': 'failed'}]\n"
     ]
    }
   ],
   "source": [
    "print(model_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
